{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f6d0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#PATHS\n",
    "VIT_PATH = '/home/maria/ProjectionSort/data/google_vit-base-patch16-224_embeddings_logits.pkl'\n",
    "NEURAL_PATH = '/home/maria/ProjectionSort/data/hybrid_neural_responses_reduced.npy'\n",
    "AREAS_PATH = '/home/maria/ProjectionSort/data/brain_area.npy'  \n",
    "\n",
    "\n",
    "# Load data\n",
    "vit = np.load(VIT_PATH, allow_pickle=True)['natural_scenes']\n",
    "R = np.load(NEURAL_PATH)            # shape: (images, neurons)\n",
    "areas = np.load(AREAS_PATH, allow_pickle=True)         # shape: (neurons,)\n",
    "\n",
    "# vit shape: (images, 1000)\n",
    "X = vit.astype(float)\n",
    "\n",
    "# center\n",
    "Xc = X - X.mean(axis=0, keepdims=True)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(Xc)\n",
    "pc1 = pca.components_[0]   # shape (1000,)\n",
    "\n",
    "print(pc1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c662e3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mirror anti-symmetry correlation: 0.13323707680721192\n"
     ]
    }
   ],
   "source": [
    "mid = 400\n",
    "\n",
    "left  = pc1[:mid]\n",
    "right = pc1[-mid:][::-1]    # reverse the tail\n",
    "\n",
    "# correlation of left with NEGATED right\n",
    "corr = np.corrcoef(left, -right)[0, 1]\n",
    "print(\"Mirror anti-symmetry correlation:\", corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af99068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal symmetry index: 1.0\n",
      "sum positive: 12.385899355660623 sum negative: 12.385899355660623\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = vit.astype(float)\n",
    "Xc = X - X.mean(axis=0, keepdims=True)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(Xc)\n",
    "pc1 = pca.components_[0]  # shape (1000,)\n",
    "\n",
    "# symmetry around horizontal axis\n",
    "mu = pc1.mean()\n",
    "v = pc1 - mu          # centered eigenvector\n",
    "\n",
    "pos = v[v > 0].sum()\n",
    "neg = -v[v < 0].sum()  # negate, so it's positive mass\n",
    "\n",
    "sym_index = min(pos, neg) / max(pos, neg)\n",
    "print(\"Horizontal symmetry index:\", sym_index)\n",
    "print(\"sum positive:\", pos, \"sum negative:\", neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f860e364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC1 mean = -9.456972857350365e-06\n",
      "PC1 min  = -0.08758162171250396\n",
      "PC1 max  = 0.127738178212524\n",
      "PC1 sum  = -0.009456972857350365\n",
      "Positive sum = 12.381785572467678\n",
      "Negative sum = -12.391242545325028\n"
     ]
    }
   ],
   "source": [
    "print(\"PC1 mean =\", pc1.mean())\n",
    "print(\"PC1 min  =\", pc1.min())\n",
    "print(\"PC1 max  =\", pc1.max())\n",
    "print(\"PC1 sum  =\", pc1.sum())\n",
    "print(\"Positive sum =\", pc1[pc1 > 0].sum())\n",
    "print(\"Negative sum =\", pc1[pc1 < 0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f8193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opponent index: 0.7737097585328523\n",
      "E_pos: 0.6131451207335741 E_neg: 0.38685487926642625\n"
     ]
    }
   ],
   "source": [
    "v = pc1  # no centering here\n",
    "\n",
    "v_pos = v[v > 0]\n",
    "v_neg = v[v < 0]\n",
    "\n",
    "E_pos = np.sum(v_pos**2)\n",
    "E_neg = np.sum(v_neg**2)\n",
    "\n",
    "opponent_index = 1 - abs(E_pos - E_neg) / (E_pos + E_neg)\n",
    "print(\"Opponent index:\", opponent_index)\n",
    "print(\"E_pos:\", E_pos, \"E_neg:\", E_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d3a9e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ViT logits: (118, 1000)\n",
      "PC1 shape: (1000,)\n",
      "Loaded ImageNet labels: 1000\n",
      "\n",
      "======================\n",
      "Top POSITIVE PC1 classes\n",
      "======================\n",
      " 291 |  0.12774 | lion\n",
      " 274 |  0.12317 | dhole\n",
      " 288 |  0.12011 | leopard\n",
      " 293 |  0.11944 | cheetah\n",
      " 271 |  0.11403 | red_wolf\n",
      " 292 |  0.10888 | tiger\n",
      " 290 |  0.10688 | jaguar\n",
      " 272 |  0.10602 | coyote\n",
      " 269 |  0.10511 | timber_wolf\n",
      " 280 |  0.10365 | grey_fox\n",
      " 286 |  0.10362 | cougar\n",
      " 275 |  0.10024 | African_hunting_dog\n",
      " 276 |  0.09944 | hyena\n",
      " 294 |  0.09882 | brown_bear\n",
      " 289 |  0.09834 | snow_leopard\n",
      " 273 |  0.09156 | dingo\n",
      " 270 |  0.09149 | white_wolf\n",
      " 287 |  0.09018 | lynx\n",
      " 278 |  0.08686 | kit_fox\n",
      " 371 |  0.08488 | patas\n",
      "\n",
      "======================\n",
      "Top NEGATIVE PC1 classes\n",
      "======================\n",
      " 421 | -0.08758 | bannister\n",
      " 879 | -0.07011 | umbrella\n",
      " 412 | -0.06883 | ashcan\n",
      " 716 | -0.06246 | picket_fence\n",
      " 703 | -0.06210 | park_bench\n",
      " 637 | -0.06106 | mailbox\n",
      " 818 | -0.06027 | spotlight\n",
      " 883 | -0.05732 | vase\n",
      " 489 | -0.05713 | chainlink_fence\n",
      " 898 | -0.05627 | water_bottle\n",
      " 880 | -0.05572 | unicycle\n",
      " 733 | -0.05510 | pole\n",
      " 706 | -0.05508 | patio\n",
      " 523 | -0.05458 | crutch\n",
      " 738 | -0.05322 | pot\n",
      " 616 | -0.05294 | knot\n",
      " 448 | -0.05277 | birdhouse\n",
      " 696 | -0.05228 | paintbrush\n",
      " 704 | -0.05185 | parking_meter\n",
      " 506 | -0.05120 | coil\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ============================================================\n",
    "# 1. PATHS — your data\n",
    "# ============================================================\n",
    "VIT_PATH = \"/home/maria/ProjectionSort/data/google_vit-base-patch16-224_embeddings_logits.pkl\"\n",
    "\n",
    "# ============================================================\n",
    "# 2. LOAD ViT logits\n",
    "# ============================================================\n",
    "vit = np.load(VIT_PATH, allow_pickle=True)[\"natural_scenes\"]\n",
    "print(\"Loaded ViT logits:\", vit.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 3. PCA → extract PC1\n",
    "# ============================================================\n",
    "X = vit.astype(float)\n",
    "Xc = X - X.mean(axis=0, keepdims=True)   # center across images\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(Xc)\n",
    "\n",
    "pc1 = pca.components_[0]       # shape: (1000,)\n",
    "print(\"PC1 shape:\", pc1.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 4. Download ImageNet 1k class index → labels mapping\n",
    "# ============================================================\n",
    "URL = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "# this is the standard mapping file used by many libraries\n",
    "resp = requests.get(URL)\n",
    "resp.raise_for_status()\n",
    "class_idx = resp.json()   # dict of str index to [synset_id, human_readable_label]\n",
    "\n",
    "# Convert to int->label dict\n",
    "idx_to_label = {int(k): v[1] for k, v in class_idx.items()}\n",
    "print(\"Loaded ImageNet labels:\", len(idx_to_label))\n",
    "\n",
    "# ============================================================\n",
    "# 5. Extract top POSITIVE & NEGATIVE classes from PC1\n",
    "# ============================================================\n",
    "k = 20   # how many to print\n",
    "\n",
    "top_pos_idx = np.argsort(pc1)[-k:][::-1]\n",
    "top_neg_idx = np.argsort(pc1)[:k]\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\"Top POSITIVE PC1 classes\")\n",
    "print(\"======================\")\n",
    "for i in top_pos_idx:\n",
    "    print(f\"{i:>4d} | {pc1[i]: .5f} | {idx_to_label.get(i, 'UNKNOWN')}\")\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\"Top NEGATIVE PC1 classes\")\n",
    "print(\"======================\")\n",
    "for i in top_neg_idx:\n",
    "    print(f\"{i:>4d} | {pc1[i]: .5f} | {idx_to_label.get(i, 'UNKNOWN')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a33a131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ViT logits: (118, 1000)\n",
      "Binary dataset shape: (41, 1000) (41,)\n",
      "Class balance: #neg = 24  #pos = 17\n",
      "Epoch  1 | loss 0.6976 | test acc 0.667\n",
      "Epoch  2 | loss 0.4924 | test acc 0.889\n",
      "Epoch  3 | loss 0.3445 | test acc 1.000\n",
      "Epoch  4 | loss 0.2428 | test acc 1.000\n",
      "Epoch  5 | loss 0.1742 | test acc 1.000\n",
      "Epoch  6 | loss 0.1279 | test acc 1.000\n",
      "Epoch  7 | loss 0.0962 | test acc 1.000\n",
      "Epoch  8 | loss 0.0740 | test acc 1.000\n",
      "Epoch  9 | loss 0.0581 | test acc 1.000\n",
      "Epoch 10 | loss 0.0464 | test acc 1.000\n",
      "Epoch 11 | loss 0.0376 | test acc 1.000\n",
      "Epoch 12 | loss 0.0310 | test acc 1.000\n",
      "Epoch 13 | loss 0.0258 | test acc 1.000\n",
      "Epoch 14 | loss 0.0218 | test acc 1.000\n",
      "Epoch 15 | loss 0.0186 | test acc 1.000\n",
      "Epoch 16 | loss 0.0161 | test acc 1.000\n",
      "Epoch 17 | loss 0.0141 | test acc 1.000\n",
      "Epoch 18 | loss 0.0124 | test acc 1.000\n",
      "Epoch 19 | loss 0.0110 | test acc 1.000\n",
      "Epoch 20 | loss 0.0099 | test acc 1.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Paths\n",
    "# -------------------------------------------------\n",
    "VIT_PATH = \"/home/maria/ProjectionSort/data/google_vit-base-patch16-224_embeddings_logits.pkl\"\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Load ViT logits\n",
    "# -------------------------------------------------\n",
    "vit = np.load(VIT_PATH, allow_pickle=True)[\"natural_scenes\"]  # (n_images, 1000)\n",
    "print(\"Loaded ViT logits:\", vit.shape)\n",
    "\n",
    "n_images, n_classes = vit.shape\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Download ImageNet labels (same as before)\n",
    "# -------------------------------------------------\n",
    "URL = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "resp = requests.get(URL)\n",
    "resp.raise_for_status()\n",
    "class_idx = resp.json()   # { \"0\": [\"n01440764\", \"tench\"], ... }\n",
    "idx_to_label = {int(k): v[1] for k, v in class_idx.items()}\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Use your discovered extremes as class sets\n",
    "# (You can tweak / expand these if you like)\n",
    "# -------------------------------------------------\n",
    "pos_classes = [\n",
    "    291, 274, 288, 293, 271, 292, 290, 272, 269, 280,\n",
    "    286, 275, 276, 294, 289, 273, 270, 287, 278, 371,\n",
    "]\n",
    "\n",
    "neg_classes = [\n",
    "    421, 879, 412, 716, 703, 637, 818, 883, 489, 898,\n",
    "    880, 733, 706, 523, 738, 616, 448, 696, 704, 506,\n",
    "]\n",
    "\n",
    "pos_set = set(pos_classes)\n",
    "neg_set = set(neg_classes)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Build a clean binary dataset\n",
    "# -------------------------------------------------\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "top1 = np.argmax(vit, axis=1)\n",
    "\n",
    "for i in range(n_images):\n",
    "    c = int(top1[i])\n",
    "    if c in pos_set:\n",
    "        X_list.append(vit[i])\n",
    "        y_list.append(1)\n",
    "    elif c in neg_set:\n",
    "        X_list.append(vit[i])\n",
    "        y_list.append(0)\n",
    "    else:\n",
    "        continue  # ignore all other images\n",
    "\n",
    "X = np.stack(X_list, axis=0)  # (N, 1000)\n",
    "y = np.array(y_list)          # (N,)\n",
    "\n",
    "print(\"Binary dataset shape:\", X.shape, y.shape)\n",
    "print(\"Class balance: #neg =\", (y == 0).sum(), \" #pos =\", (y == 1).sum())\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Train/test split\n",
    "# -------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test_t  = torch.tensor(X_test,  dtype=torch.float32).to(device)\n",
    "y_test_t  = torch.tensor(y_test,  dtype=torch.float32).to(device)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Single \"animal neuron\" model\n",
    "# -------------------------------------------------\n",
    "class AnimalNeuron(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, 1)  # w, b\n",
    "\n",
    "    def forward(self, x):\n",
    "        # returns probability in (0,1)\n",
    "        return torch.sigmoid(self.linear(x)).squeeze(-1)\n",
    "\n",
    "model = AnimalNeuron(n_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Training loop (tiny, just a few epochs)\n",
    "# -------------------------------------------------\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "def batches(X, y, bs):\n",
    "    n = X.shape[0]\n",
    "    idx = torch.randperm(n)\n",
    "    for start in range(0, n, bs):\n",
    "        end = min(start + bs, n)\n",
    "        sel = idx[start:end]\n",
    "        yield X[sel], y[sel]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for xb, yb in batches(X_train_t, y_train_t, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    epoch_loss /= X_train_t.shape[0]\n",
    "\n",
    "    # quick evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_test = model(X_test_t)\n",
    "        pred_labels = (preds_test > 0.5).float()\n",
    "        acc = (pred_labels == y_test_t).float().mean().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:2d} | loss {epoch_loss:.4f} | test acc {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95ddc6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamics for a 'lion' image:\n",
      "t=0  h=0.992\n",
      "t=1  h=0.997\n",
      "t=2  h=0.997\n",
      "t=3  h=0.997\n",
      "t=4  h=0.997\n",
      "t=5  h=0.997\n",
      "t=6  h=0.997\n",
      "t=7  h=0.997\n",
      "t=8  h=0.997\n",
      "t=9  h=0.997\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def run_dynamics(x_np, model, alpha=0.9, T=10):\n",
    "    \"\"\"\n",
    "    x_np: numpy array shape (1000,)\n",
    "    model: trained AnimalNeuron\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        w = model.linear.weight.detach().cpu()[0]  # (1000,)\n",
    "        b = model.linear.bias.detach().cpu().item()\n",
    "\n",
    "    x = torch.tensor(x_np, dtype=torch.float32)\n",
    "    h = torch.tensor(0.0)\n",
    "\n",
    "    traj = []\n",
    "    for t in range(T):\n",
    "        h_in = torch.dot(w, x) + b + alpha * h\n",
    "        h = torch.sigmoid(h_in)\n",
    "        traj.append(h.item())\n",
    "\n",
    "    return traj\n",
    "\n",
    "# Example: pick an image that ViT thinks is a lion\n",
    "example_idx = np.where(top1 == 291)[0][0]  # top1 from before\n",
    "traj_lion = run_dynamics(vit[example_idx], model, alpha=0.9, T=10)\n",
    "\n",
    "print(\"Dynamics for a 'lion' image:\")\n",
    "for t, h_t in enumerate(traj_lion):\n",
    "    print(f\"t={t}  h={h_t:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
